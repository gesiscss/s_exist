{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec18d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/pyparsing.py:3190: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile(self.reString)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from preprocessing import preprocess\n",
    "from utils import read_train, build_feature_path, read_train_no_validation, read_test, read_validation\n",
    "import autosklearn\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import autosklearn.classification\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "253d6748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read training data\n",
      "read precomputed feature boosters_selected\n",
      "read precomputed feature char_prediction\n",
      "read precomputed feature hashtags_selected\n",
      "read precomputed feature hedges_selected\n",
      "read precomputed feature mentions_total\n",
      "read precomputed feature female_words\n",
      "read precomputed feature male_words\n",
      "read precomputed feature most_similar_scale\n",
      "read precomputed feature perspective\n",
      "read precomputed feature perspective_difference\n",
      "read precomputed feature sif\n",
      "read precomputed feature vader_selected\n",
      "encode language\n",
      "preprocess text\n",
      "X.shape (5581, 882) y.shape (5581,) unique y [0 1]\n"
     ]
    }
   ],
   "source": [
    "print('read training data')\n",
    "train = read_train()\n",
    "features = [\n",
    "#     'bert_multiclass',\n",
    "    'boosters_selected', \n",
    "    'char_prediction',\n",
    "    'hashtags_selected',\n",
    "    'hedges_selected',\n",
    "    'mentions_total',\n",
    "    'female_words',\n",
    "    'male_words',\n",
    "    'most_similar_scale',\n",
    "    'perspective',\n",
    "    'perspective_difference',\n",
    "    'sif',\n",
    "    'vader_selected'\n",
    " ]\n",
    "for feature in features:\n",
    "    print('read precomputed feature', feature)\n",
    "    feature_path = build_feature_path('TRAINING_REL', feature)\n",
    "    feature_df = pd.read_csv(feature_path, index_col='id')\n",
    "    feature_df.columns = [feature + \"_\" + column for column in feature_df.columns]\n",
    "    train = pd.merge(train, feature_df, how='left', left_index=True, right_index=True)\n",
    "print('encode language')\n",
    "language_le = LabelEncoder()\n",
    "train['language'] = language_le.fit_transform(train.language)\n",
    "print('preprocess text')\n",
    "train['text'] = train.text.apply(partial(preprocess, fix_encoding=True))\n",
    "features += ['language', 'text']\n",
    "\n",
    "train_ = train.loc[read_train_no_validation().index]\n",
    "X = train_[[column for column in train.columns if any(column.startswith(feature) for feature in features)]]\n",
    "\n",
    "y = train_.task1.values\n",
    "y_le = LabelEncoder()\n",
    "y = y_le.fit_transform(y)\n",
    "\n",
    "print('X.shape', X.shape, 'y.shape', y.shape, 'unique y', np.unique(y))\n",
    "labels = y_le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a0b8c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in X.columns if col.startswith('bert')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad99260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "char = ColumnTransformer(transformers=[('cv', Pipeline(steps=[('cv', CountVectorizer(analyzer='char',\n",
    "                                                                  ngram_range=(3, 4))),\n",
    "                                                                  ('fs',SelectFromModel(estimator=MultinomialNB(),\n",
    "                                                                                       max_features=1000)  # use multitask in case of task2\n",
    "                                        )]), 'text'),\n",
    "                                       \n",
    "                                       ('scale',  CountVectorizer(), 'most_similar_scale_scale'),\n",
    "                         ('content',  CountVectorizer(), 'most_similar_scale_sexist_content'),\n",
    "#                          ('bert',  CountVectorizer(), 'bert_multiclass_predictions'),\n",
    "                                      ],\n",
    "                             remainder='passthrough'\n",
    "                             )\n",
    "X_char = char.fit_transform(X.fillna('dontknow'), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "85cabc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [50, 100, 200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [3, 5, 7, 10,]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "              'criterion':[\"gini\", \"entropy\"],\n",
    "               'class_weight':['balanced_subsample']\n",
    "                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8900e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, refit=True, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "41ef5714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=20,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'class_weight': ['balanced_subsample'],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [3, 5, 7, 10],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 100, 200]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.fit(X_char.astype(float), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "14988e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/bigdata/sexism/utils/temp/autosklearn_out/task1_gridsearch.pickle','wb+') as f:\n",
    "    pickle.dump(automl, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fb52710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (1396, 882) y.shape (1396,) unique y [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "validation = train.loc[read_validation().index]\n",
    "X = validation[[column for column in train.columns if any(column.startswith(feature) for feature in features)]]\n",
    "\n",
    "y = validation.task1.values\n",
    "y = y_le.transform(y)\n",
    "\n",
    "print('X.shape', X.shape, 'y.shape', y.shape, 'unique y', np.unique(y))\n",
    "labels = y_le.classes_\n",
    "X_char = char.transform(X.fillna('dontknow'))\n",
    "y_pred = automl.predict(X_char.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cf24d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.92      0.84      0.88       720\n",
      "      sexist       0.84      0.93      0.88       676\n",
      "\n",
      "    accuracy                           0.88      1396\n",
      "   macro avg       0.88      0.88      0.88      1396\n",
      "weighted avg       0.88      0.88      0.88      1396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y, y_pred=y_pred, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9154eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test data\n",
      "read precomputed feature boosters_selected\n",
      "read precomputed feature char_prediction\n",
      "read precomputed feature hashtags_selected\n",
      "read precomputed feature hedges_selected\n",
      "read precomputed feature mentions_total\n",
      "read precomputed feature female_words\n",
      "read precomputed feature male_words\n",
      "read precomputed feature most_similar_scale\n",
      "read precomputed feature perspective\n",
      "read precomputed feature perspective_difference\n",
      "read precomputed feature sif\n",
      "read precomputed feature vader_selected\n",
      "encode language\n",
      "preprocess text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://78.media.tumblr.com/48eb3176d85e2c931265636c5b350571/tumblr_owydjaJVu31vk1vm0o1_1280.jpg#gamergate\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://ussanews.com/News1/2017/06/13/liberals-triggered-by-sessions-mansplaining-to-democrat-kamala-harris/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://www.theguardian.com/commentisfree/2018/oct/16/hating-men-crime-eldely-women-sajid-david-misandry \" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://www.blazingcatfur.ca/2017/11/09/alberta-premier-accuses-male-mlas-of-mansplaining-and-hepeating-over-pipelines/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.breitbart.com/london/2018/04/26/rotherham-child-rape-scandal-100-investigations-police-potential-misconduct/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://www.spectator.com.au/2018/11/the-week-in-misandry-6/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://es.dailystormer.name/2018/06/23/detados-hombre-marroqui-por-violacion-y-asesinato-de-activista-proinmigracion/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://www.mediterraneodigital.com/espana/cataluna/los-terroristas-de-barcelona-se-iban-de-putas-miento-cobraban-ayudas-sociales.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://noapodemos.com/costimonio-importadas-13-anos-violar-amenazar-muerte-hija-menor-edad\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://elmed.io/mahmud-abas-llama-hijo-de-perra-al-embajador-de-eeuu-en-israel/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://evolucionyneurociencias.blogspot.com.co/2016/12/las-mujeres-no-cobran-menos-que-los.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://ecodiario.eleconomista.es/internacional/noticias/9024351/03/18/Detenidos-10-argelinos-en-Espana-por-agredir-sexually-a-chicas-menores.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.elmatinal.com/espana/detienen-a-otro-marroqui-por-intentar-violar-a-dos-chicas-de-16-anos-en-murcia/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.abc.es/espana/abci-celula-daesh-atentar-espana-querian-liarla-gorda-201805090308_noticia.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://www.esdiario.com/610882287/Polemica-El-Pais-ataca-a-La-Sexta-por-convertirse-en-un-comisiarado-feminazi.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.abc.es/espana/comunidad-valenciana/abci-manada-argelina-nueva-agresion-sexual-grupo-chica-alicante-201804161330_noticia.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://noapodemos.com/video-refugiados-agreden-brutalmente-una-chica-robarle-una-bíritu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://casoaislado.com/otra-vez-alicante-tres-argelinos-detenidos-tras-una-nueva-violacion-grupal/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.periodistadigital.com/politica/partidos-politicos/2018/03/09/feminismo-huelga-mujeres-tetas-gordas-proces-erc-esquerra-puesto.shtml\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('read test data')\n",
    "test = read_test()\n",
    "for feature in features:\n",
    "    if feature in ['language', 'text']:continue\n",
    "    print('read precomputed feature', feature)\n",
    "    feature_path = build_feature_path('TEST_REL', feature)\n",
    "    feature_df = pd.read_csv(feature_path, index_col='id')\n",
    "    feature_df.columns = [feature + \"_\" + column for column in feature_df.columns]\n",
    "    test = pd.merge(test, feature_df, how='left', left_index=True, right_index=True)\n",
    "print('encode language')\n",
    "test['language'] = language_le.fit_transform(test.language)\n",
    "print('preprocess text')\n",
    "test['text'] = test.text.apply(partial(preprocess, fix_encoding=True))\n",
    "\n",
    "X_test = test[[column for column in train.columns if any(column.startswith(feature) for feature in features)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6ce2a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/samory/exist/s_exist/sexist_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_char = char.transform(X_test.fillna('dontknow'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5c0693f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = automl.predict(X_test_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1f00006",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred= y_le.inverse_transform(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4bec3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-sexist', 'sexist'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "930e2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pd.Series(y_test_pred, index=test.index, name='task1')).reset_index().transform({'id':lambda x: \"{:06d}\".format(x),\n",
    "                                                                                             'task1':lambda x:x}).to_csv('/bigdata/sexism/utils/temp/autosklearn_out/task1_gridsearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c20d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(y_test_pred, index=test.index, name='task1')).reset_index().transform({'id':lambda x: \"{:06d}\".format(x),\n",
    "                                                                                             'task1':lambda x:x})\n",
    "results_df['test_case'] = 'EXIST2021'\n",
    "results_df[['test_case', 'id', 'task1']].to_csv('/bigdata/sexism/utils/temp/autosklearn_out/task1_gridsearch.tsv', sep='\\t', header = None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2dd71c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'criterion': 'gini',\n",
       " 'class_weight': 'balanced_subsample',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153b4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9acc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exist-venv",
   "language": "python",
   "name": "exist-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
