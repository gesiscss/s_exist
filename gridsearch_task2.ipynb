{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from preprocessing import preprocess\n",
    "from utils import read_train, build_feature_path, read_train_no_validation, read_test, read_validation\n",
    "import autosklearn\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import autosklearn.classification\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "253d6748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read training data\n",
      "read precomputed feature boosters_selected\n",
      "read precomputed feature char_prediction\n",
      "read precomputed feature hashtags_selected\n",
      "read precomputed feature hedges_selected\n",
      "read precomputed feature mentions_total\n",
      "read precomputed feature female_words\n",
      "read precomputed feature male_words\n",
      "read precomputed feature most_similar_scale\n",
      "read precomputed feature perspective\n",
      "read precomputed feature perspective_difference\n",
      "read precomputed feature sif\n",
      "read precomputed feature vader_selected\n",
      "encode language\n",
      "preprocess text\n",
      "X.shape (5581, 882) y.shape (5581,) unique y [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print('read training data')\n",
    "train = read_train()\n",
    "features = [\n",
    "    'boosters_selected', \n",
    "    'char_prediction',\n",
    "    'hashtags_selected',\n",
    "    'hedges_selected',\n",
    "    'mentions_total',\n",
    "    'female_words',\n",
    "    'male_words',\n",
    "    'most_similar_scale',\n",
    "    'perspective',\n",
    "    'perspective_difference',\n",
    "    'sif',\n",
    "    'vader_selected'\n",
    " ]\n",
    "for feature in features:\n",
    "    print('read precomputed feature', feature)\n",
    "    feature_path = build_feature_path('TRAINING_REL', feature)\n",
    "    feature_df = pd.read_csv(feature_path, index_col='id')\n",
    "    feature_df.columns = [feature + \"_\" + column for column in feature_df.columns]\n",
    "    train = pd.merge(train, feature_df, how='left', left_index=True, right_index=True)\n",
    "print('encode language')\n",
    "language_le = LabelEncoder()\n",
    "train['language'] = language_le.fit_transform(train.language)\n",
    "print('preprocess text')\n",
    "train['text'] = train.text.apply(partial(preprocess, fix_encoding=True))\n",
    "features += ['language', 'text']\n",
    "features += ['language']\n",
    "\n",
    "train_ = train.loc[read_train_no_validation().index]\n",
    "X = train_[[column for column in train.columns if any(column.startswith(feature) for feature in features)]]\n",
    "\n",
    "y = train_.task2.values\n",
    "y_le = LabelEncoder()\n",
    "y = y_le.fit_transform(y)\n",
    "\n",
    "print('X.shape', X.shape, 'y.shape', y.shape, 'unique y', np.unique(y))\n",
    "labels = y_le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = ColumnTransformer(transformers=[\n",
    "    ('cv', Pipeline(steps=[('cv', CountVectorizer(analyzer='char',\n",
    "                                                                  ngram_range=(3, 4))),\n",
    "                                                                  ('fs',SelectFromModel(estimator=MultinomialNB())  # use multitask in case of task2\n",
    "                                        )]), 'text'),\n",
    "                                       \n",
    "                                       ('scale',  CountVectorizer(), 'most_similar_scale_scale'),\n",
    "                         ('content',  CountVectorizer(), 'most_similar_scale_sexist_content'),\n",
    "                                      ],\n",
    "                             remainder='passthrough'\n",
    "                             )\n",
    "X_char = char.fit_transform(X.fillna('dontknow'), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38db111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [50, 100, 200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [3, 5, 7, 10,]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "              'criterion':[\"gini\", \"entropy\"],\n",
    "               'class_weight':['balanced']\n",
    "                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a8dd676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, refit=True, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7eddf0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=20,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'class_weight': ['balanced'],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [3, 5, 7, 10],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 100, 200]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.fit(X_char.astype(float), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "14988e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2_gridsearch.pickle','wb+') as f:\n",
    "    pickle.dump(automl, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = train.loc[read_validation().index]\n",
    "X = validation[[column for column in train.columns if any(column.startswith(feature) for feature in features)]]\n",
    "\n",
    "y = validation.task2.values\n",
    "y = y_le.transform(y)\n",
    "\n",
    "print('X.shape', X.shape, 'y.shape', y.shape, 'unique y', np.unique(y))\n",
    "labels = y_le.classes_\n",
    "X_char = X\n",
    "X_char = char.transform(X.fillna('dontknow'))\n",
    "y_pred = automl.predict(X_char.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf24d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.66      0.94      0.77       173\n",
      "misogyny-non-sexual-violence       0.67      0.92      0.77       137\n",
      "                  non-sexist       0.96      0.61      0.74       720\n",
      "             objectification       0.93      0.95      0.94       100\n",
      "             sexual-violence       0.59      0.99      0.74       104\n",
      "      stereotyping-dominance       0.63      0.88      0.73       162\n",
      "\n",
      "                    accuracy                           0.76      1396\n",
      "                   macro avg       0.74      0.88      0.78      1396\n",
      "                weighted avg       0.82      0.76      0.76      1396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y, y_pred=y_pred, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7033cd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.61      0.74       720\n",
      "      sexist       0.70      0.97      0.81       676\n",
      "\n",
      "    accuracy                           0.78      1396\n",
      "   macro avg       0.83      0.79      0.78      1396\n",
      "weighted avg       0.83      0.78      0.78      1396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=(y!=2), y_pred=(y_pred!=2), target_names=['non-sexist', 'sexist']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9154eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test data\n",
      "read precomputed feature boosters_selected\n",
      "read precomputed feature char_prediction\n",
      "read precomputed feature hashtags_selected\n",
      "read precomputed feature hedges_selected\n",
      "read precomputed feature mentions_total\n",
      "read precomputed feature female_words\n",
      "read precomputed feature male_words\n",
      "read precomputed feature most_similar_scale\n",
      "read precomputed feature perspective\n",
      "read precomputed feature perspective_difference\n",
      "read precomputed feature sif\n",
      "read precomputed feature vader_selected\n",
      "encode language\n"
     ]
    }
   ],
   "source": [
    "print('read test data')\n",
    "test = read_test()\n",
    "for feature in features:\n",
    "    if feature in ['language', 'text']:continue\n",
    "    print('read precomputed feature', feature)\n",
    "    feature_path = build_feature_path('TEST_REL', feature)\n",
    "    feature_df = pd.read_csv(feature_path, index_col='id')\n",
    "    feature_df.columns = [feature + \"_\" + column for column in feature_df.columns]\n",
    "    test = pd.merge(test, feature_df, how='left', left_index=True, right_index=True)\n",
    "print('encode language')\n",
    "test['language'] = language_le.fit_transform(test.language)\n",
    "# print('preprocess text')\n",
    "# test['text'] = test.text.apply(partial(preprocess, fix_encoding=True))\n",
    "\n",
    "X_test = test[[column for column in train.columns if any(column.startswith(feature) for feature in features)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_char = char.transform(X_test.fillna('dontknow'))\n",
    "# X_test_char = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5c0693f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = automl.predict(X_test_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f1f00006",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred= y_le.inverse_transform(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4bec3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ideological-inequality', 'misogyny-non-sexual-violence',\n",
       "       'non-sexist', 'objectification', 'sexual-violence',\n",
       "       'stereotyping-dominance'], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "930e2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pd.Series(y_test_pred, index=test.index, name='task2')).reset_index().transform({'id':lambda x: \"{:06d}\".format(x),\n",
    "                                                                                             'task2':lambda x:x}).to_csv('task2_gridsearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3c20d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(y_test_pred, index=test.index, name='task2')).reset_index().transform({'id':lambda x: \"{:06d}\".format(x),\n",
    "                                                                                             'task2':lambda x:x})\n",
    "results_df['test_case'] = 'EXIST2021'\n",
    "results_df[['test_case', 'id', 'task2']].to_csv('task2_gridsearch.tsv', sep='\\t', header = None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2dd71c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'criterion': 'entropy',\n",
       " 'class_weight': 'balanced',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d64ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac99371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exist-venv",
   "language": "python",
   "name": "exist-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
